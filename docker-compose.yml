services:
  next-app:
    image: node:20-alpine
    working_dir: /app
    command: sh -c "npm install && npm run dev"
    ports:
      - "3000:3000"
    environment:
      - WEAVIATE_URL=http://weaviate:8080
      - WEAVIATE_API_KEY=my-secret-weaviate-key-2024
      - GROQ_API_KEY=${GROQ_API_KEY}
    volumes:
      - ./next-app:/app
      - next_node_modules:/app/node_modules
    depends_on:
      weaviate:
        condition: service_healthy
    restart: unless-stopped

  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_APIKEY_ENABLED: "true"
      AUTHENTICATION_APIKEY_ALLOWED_KEYS: "my-secret-weaviate-key-2024"
      AUTHENTICATION_APIKEY_USERS: "admin@weaviate.local"
      AUTHORIZATION_ADMINLIST_ENABLED: "true"
      AUTHORIZATION_ADMINLIST_USERS: "admin@weaviate.local"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      DEFAULT_VECTORIZER_MODULE: "text2vec-transformers"
      ENABLE_MODULES: "text2vec-transformers"
      TRANSFORMERS_INFERENCE_API: "http://t2v-transformers:8080"
      CLUSTER_HOSTNAME: "node1"
    volumes:
      - weaviate_data:/var/lib/weaviate
    depends_on:
      t2v-transformers:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 5s
      timeout: 3s
      retries: 15
    restart: unless-stopped

  t2v-transformers:
    image: cr.weaviate.io/semitechnologies/transformers-inference:sentence-transformers-all-MiniLM-L6-v2
    environment:
      ENABLE_CUDA: "0"
    restart: unless-stopped

volumes:
  weaviate_data:
  next_node_modules:
